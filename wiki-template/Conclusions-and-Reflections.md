
## Conclusions and Learnings

In conclusion, our evaluation of the three AI agents, utilizing Greedy Best-First Search (BFS), Value Iteration, and Monte-Carlo Tree Search (MCTS) has revealed that both Value Iteration and MCTS outperform BFS significantly. However, we have noticed that our MCTS and Value Iteration algorithms exhibit similar performance rates.

When pitted against each other, the win rates of MCTS and Value Iteration are remarkably close. Nevertheless, MCTS possesses a distinct advantage in terms of computational efficiency as it executes faster and more efficiently compared to Value Iteration.

Reflecting on our findings, we can draw the following insights:
1. Algorithm Comparison: Our comparative analysis highlights the limitations of BFS and the advantage of more sophisticated algorithms such as Value Iteration and MCTS. This reinforces the importance of leveraging advanced techniques to achieve better performance.
2. Computational Efficiency: The advantage of MCTS in terms of computational efficiency demonstrates its potential for other real-time and resource-constrained applications beside playing Azul. This makes MCTS a much better choice in wider range of areas, especially when time and computational resources are limited.
3. Continuous Learning: Through our journey of coding these complex AI algorithms, we have gained valuable lessons of coding techniques for BFS, Value Iteration, and MCTS. While we successfully implemented selection, expansion, and simulation stages in MCTS, we faced challenges with backpropagation. This experience serves as a valuable lesson for future endeavors and highlights the importance of continuous learning and improvement.
